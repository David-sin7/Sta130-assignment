{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c152c78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id    0\n",
       "q1            0\n",
       "q2            0\n",
       "q3            0\n",
       "q4            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prelecture question 1 \n",
    "import pandas as pd\n",
    "url = \"https://gist.githubusercontent.com/ycui1/dd33483219aeec871b9137a1e7925235/raw/6ae3e4e51b4807313068244dd315eb5e0a989827/pandas_missing_values_dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47bf0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 20 rows and 5 columns.\n"
     ]
    }
   ],
   "source": [
    "#Prelecture qusetion 1 1)\n",
    "rows, columns = df.shape\n",
    "print(f'The dataset has {rows} rows and {columns} columns.')\n",
    "\n",
    "#Prelecture qusetion 1 2)\n",
    "#Observation is data or answers collected from a specific substance or scene.\n",
    "#variables are some specific attributes or responses from the subjects in certain conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc2d9b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary:\n",
      "        subject_id\n",
      "count    20.00000\n",
      "mean   1010.50000\n",
      "std       5.91608\n",
      "min    1001.00000\n",
      "25%    1005.75000\n",
      "50%    1010.50000\n",
      "75%    1015.25000\n",
      "max    1020.00000\n",
      "\n",
      "Value Counts for column 'q2':\n",
      " q2\n",
      "Agree             5\n",
      "Disagree          5\n",
      "-                 5\n",
      "Strongly Agree    3\n",
      "Neutral           2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts for column 'q4':\n",
      " q4\n",
      "5     3\n",
      "8     3\n",
      "?     3\n",
      "7     3\n",
      "9     2\n",
      "-     1\n",
      "4     1\n",
      "12    1\n",
      "1     1\n",
      "3     1\n",
      "10    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Prelecture qusetion 2\n",
    "data = pd.read_csv('https://gist.githubusercontent.com/ycui1/dd33483219aeec871b9137a1e7925235/raw/6ae3e4e51b4807313068244dd315eb5e0a989827/pandas_missing_values_dataset.csv')\n",
    "\n",
    "summary = data.describe()\n",
    "print(\"Statistical Summary:\\n\", summary)\n",
    "\n",
    "value_counts_q2 = data['q2'].value_counts()\n",
    "print(\"\\nValue Counts for column 'q2':\\n\", value_counts_q2)\n",
    "\n",
    "value_counts_q4 = data['q4'].value_counts()\n",
    "print(\"\\nValue Counts for column 'q4':\\n\", value_counts_q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2082d",
   "metadata": {},
   "source": [
    "Prelecture qusetion 3\n",
    "df.shape will give the size of the dataset including the missing value\n",
    "df.describe() will tell us how many columns contain numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db5c58",
   "metadata": {},
   "source": [
    "Prelecture qusetion 4\n",
    "a） An attribute stores some kind of value or information about the object,\n",
    "A method is a function that you can call to perform operations or calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff5fdd",
   "metadata": {},
   "source": [
    "#post-lecture question 6\n",
    "Definition: \n",
    "Count:\n",
    "The number of non-missing (non-NaN) values in the column. It represents how many valid entries are available for each variable.\n",
    "\n",
    "Mean:\n",
    "The average of the values in the column, calculated by summing all non-missing values and dividing by the count of those values\n",
    "\n",
    "Std (Standard Deviation):\n",
    "A measure of the spread or dispersion of the values in the column. It shows how much the values deviate, on average, from the mean. A higher standard deviation indicates more variability.\n",
    "\n",
    "Min:\n",
    "The minimum or smallest value in the column.\n",
    "\n",
    "25% (First Quartile):\n",
    "This is the value below which 25% of the data falls. It’s also called the first quartile (Q1). It gives a sense of the lower part of the data distribution.\n",
    "\n",
    "50% (Median or Second Quartile):\n",
    "The median value, also called the second quartile (Q2). This is the middle value that separates the lower half and the upper half of the data. In other words, 50% of the data lies below this value.\n",
    "\n",
    "75% (Third Quartile):\n",
    "This is the value below which 75% of the data falls, also called the third quartile (Q3). It gives a sense of the upper part of the data distribution.\n",
    "\n",
    "Max:\n",
    "The maximum or largest value in the column.\n",
    "\n",
    "Why These Statistics Only Apply to Numeric Variables:\n",
    "These summary statistics—mean, standard deviation, and percentiles—are only meaningful for numeric data. They require mathematical operations (like summing or calculating deviations), which don’t make sense for categorical or string variables. This is why df.describe() by default only analyzes numeric columns.\n",
    "\n",
    "How df.describe() Handles Missing Data:\n",
    "Missing values (NaNs) are ignored when calculating statistics. This means that df.describe() computes statistics only on the non-missing (valid) values in the column.(For example, if a column has 10 rows but 2 of them are missing, the count will be 8, and the mean, standard deviation, etc., will be calculated based on those 8 valid values.)\n",
    "Count will reflect the number of non-missing values for each variable, not the total number of rows in the dataset. This is important when there are missing values, as it indicates how many data points were actually used to compute the statistics.\n",
    "\n",
    "Implications for Handling Missing Data:\n",
    "df.describe() handles missing values implicitly by excluding them from the calculations. It can still provide meaningful summaries, which suggests that missing data doesn't always need to be removed before using certain methods.However, not all methods in data analysis handle missing data the same way. For example, certain machine learning models or statistical tests may fail or produce inaccurate results if missing values are not explicitly addressed (e.g., by removing them or filling them in through imputation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb121f02",
   "metadata": {},
   "source": [
    "post-lecture question 7:\n",
    "1) In a medical dataset where each row represents a patient, if only a few patients have missing data for certain variables, you might choose to eliminate those specific rows using df.dropna(), ensuring that the remaining dataset stays complete.\n",
    "\n",
    "2) In a customer survey dataset with a column for optional comments where 80% of the data is missing, you could choose to remove that comments column entirely using del df['col'] since it doesn’t add much to your analysis, preserving the more valuable customer demographic data.\n",
    "\n",
    "3) Deleting the column with many missing values before using df.dropna() can be important. By removing the column first, you decrease the overall number of missing data points, meaning fewer rows will be dropped by df.dropna(). If you don’t remove the column beforehand, df.dropna() could delete rows unnecessarily, causing you to lose data that is still useful in other parts of the dataset.\n",
    "\n",
    "4) \n",
    "before \n",
    "Before:\n",
    "\n",
    "Name\tEmail\tPhone\tAge\tFeedback\n",
    "John\tjohn@example.com\t123-456-7890\t28\tNaN\n",
    "Alice\talice@example.com\tNaN\t35\tGreat service\n",
    "Bob\tbob@example.com\t987-654-3210\tNaN\tNaN\n",
    "Carol\tcarol@example.com\tNaN\t22\tGood experience\n",
    "\n",
    "\n",
    "after: \n",
    "John\tjohn@example.com\t123-456-7890\t28\n",
    "\n",
    "Further Guidance: \n",
    "Making a Copy of Data:\n",
    "Before making any modifications to your dataset, it's a good practice to create a backup copy. This ensures you can always \"undo\" or revert changes by reloading the original copy if something doesn't work as expected.\n",
    "Undoing Changes:\n",
    "If changes made to the dataset are not what you expected, you can restore the original dataset using the backup copy (df_saved). This is why creating a copy is so important before making modifications.\n",
    "Checking the State of Data:\n",
    "You need to ensure that the state of the dataset (df) aligns with what your code expects. If you previously ran code that modified the dataset and didn’t save a copy, the structure may no longer match the assumptions of the current code.\n",
    "Before executing new code, always double-check the structure of your dataframe using df.info() or df.head() to verify that it looks as expected.\n",
    "Handling Errors:\n",
    "If you encounter Python errors, you can copy and paste the error message here, and I can assist in troubleshooting it.\n",
    "It’s also important to make sure the objects (dataframes, lists, etc.) in your environment haven’t been unexpectedly changed or deleted, which could lead to errors like NameError or KeyError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92674c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for 7.4:\n",
    "    import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Carol'],\n",
    "    'Email': ['john@example.com', 'alice@example.com', 'bob@example.com', 'carol@example.com'],\n",
    "    'Phone': ['123-456-7890', None, '987-654-3210', None],\n",
    "    'Age': [28, 35, None, 22],\n",
    "    'Feedback': [None, 'Great service', None, 'Good experience']\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "before_report = df.copy()\n",
    "\n",
    "\n",
    "del df['Feedback']\n",
    "\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "\n",
    "after_report = df_cleaned.copy()\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Before Data Cleanup\", dataframe=before_report)\n",
    "tools.display_dataframe_to_user(name=\"After Data Cleanup\", dataframe=after_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc5cb41",
   "metadata": {},
   "source": [
    "Question 8: \n",
    "1. It groups the data by unique values in col1 and describe col2 in each group including using Count, Mean, Standard deviation, Min, 25%, 50%, and 75% percentiles, Max\n",
    "example: \n",
    "pclass\tsurvived\tname\tsex\tage\tsibsp\tparch\tticket\tfare\tcabin\tembarked\tboat\tbody\thome.dest\n",
    "1\t1\tLurette, Miss. Elise\tfemale\t58\t0\t0\tPC 17569\t146.5208\tB80\tC\t\t\t\n",
    "1\t1\tMadill, Miss. Georgette Alexandra\tfemale\t15\t0\t1\t24160\t211.3375\tB5\tS\t2\t\tSt Louis, MO\n",
    "2\t1\tFaunthorpe, Mrs. Lizzie (Elizabeth Anne Wilkinson)\tfemale\t29\t1\t0\t2926\t26.0000\t\tS\t16\t\t\n",
    "2\t0\tFillbrook, Mr. Joseph Charles\tmale\t18\t0\t0\tC.A. 15185\t10.5000\t\tS\t\t\tCornwall / Houghton, MI\n",
    "if I used it as an example, the code will be df.groupby(\"pclass\")[\"fare\"].describe(). then the code will group them using pclass and using the data in age to make anaylze. and the answer output will be \n",
    "\n",
    "        count      mean         std        min        25%        50%        75%        max\n",
    "pclass                                                                                    \n",
    "1       3.0      189.7320    37.306      146.5208    178.9292    211.3375   211.3375   211.3375\n",
    "2       2.0       18.2500    10.964      10.5000     14.3750     18.2500    22.1250    26.0000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf447c7",
   "metadata": {},
   "source": [
    "Question 8: \n",
    "2 df.describe will analyze each row indepently for each non-missing value. df.groupby(\"col1\")[\"col2\"].describe() is using col1 to seperate them into different group and then using the value of col2 to analyze.\n",
    "3.Compared to Google Search, ChatGPT is better at analyzing and explaining code, as well as providing possible advice and suggestions. Google Search relies on users' or companies' past responses. So i believe chatgpt is better than the google search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170552d3",
   "metadata": {},
   "source": [
    "Question 9:\n",
    "Yeah, really hard to understand in first time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a9037",
   "metadata": {},
   "source": [
    "#summary \n",
    "#Here’s a summary of the key points covered in this session:\n",
    "\n",
    "#Dataset Summarization:\n",
    "\n",
    "#We reviewed how to use df.describe() for summarizing numeric columns and df['column'].value_counts() for counting unique values in specific columns.\n",
    "#You learned how df.describe() provides statistics like count, mean, and standard deviation for numeric columns, and how df['column'].value_counts() is useful for counting occurrences in categorical columns.\n",
    "\n",
    "#Differences Between df.shape and df.describe():\n",
    "#df.shape reports the total number of rows and columns in the dataset, regardless of missing values or data types.\n",
    "#df.describe() provides statistics only for numeric columns by default, and the count reflects only non-missing values.\n",
    "\n",
    "#Understanding Attributes and Methods:\n",
    "#Attributes (like df.shape) store a specific value or information about the DataFrame without performing any calculations.\n",
    "#Methods (like df.describe()) are functions that perform operations or calculations when called with parentheses ().\n",
    "\n",
    "#Handling Missing Values:\n",
    "#You learned that the \"count\" reported by df.describe() reflects only non-missing values, which may lead to discrepancies between the total rows in df.shape and the count in df.describe() when missing data is present.\n",
    "\n",
    "#Clarification of Attributes and Methods:\n",
    "#Attributes store values directly related to an object (e.g., DataFrame dimensions), while methods perform operations on the object (e.g., calculating statistics or transforming data).\n",
    "#ChatGpt link : https://chatgpt.com/share/a67aa256-124c-46e2-a8e8-ce48aaf06c6c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c9e4f",
   "metadata": {},
   "source": [
    "Chatgpt Summary before Question 7:\n",
    "Understanding Attributes vs. Methods in Pandas:\n",
    "\n",
    "Attributes (like df.shape) store properties about the DataFrame, such as its size, and do not require parentheses ().\n",
    "Methods (like df.describe()) are functions that perform calculations or operations on the DataFrame, requiring parentheses to execute.\n",
    "Using df.describe() and df['column'].value_counts():\n",
    "\n",
    "df.describe() provides summary statistics for numeric columns, such as count, mean, standard deviation, min, max, and percentiles (25%, 50%, and 75%).\n",
    "df['column'].value_counts() counts the occurrences of unique values in a column, particularly useful for categorical data.\n",
    "Discrepancies Between df.shape and df.describe():\n",
    "\n",
    "df.shape reports the total number of rows and columns in the dataset, including missing values.\n",
    "df.describe() only calculates summary statistics for non-missing values and applies only to numeric columns unless otherwise specified.\n",
    "The \"count\" in df.describe() represents the number of non-missing values, which can be less than the total number of rows due to missing data.\n",
    "Handling Missing Data in df.describe():\n",
    "\n",
    "df.describe() automatically handles missing data by excluding NaN values from its calculations. This means it still provides summary statistics even if there are missing values in the column.\n",
    "Not all methods handle missing data as gracefully as df.describe() does, so sometimes it is necessary to explicitly remove or impute missing values.\n",
    "Definitions of Summary Statistics:\n",
    "\n",
    "Count: Number of non-missing values in the column.\n",
    "Mean: Average of non-missing values.\n",
    "Std: Standard deviation, showing the spread of the data.\n",
    "Min: Smallest value.\n",
    "25%, 50%, 75%: Percentiles representing the distribution of the data.\n",
    "Max: Largest value.\n",
    "Working with Non-Numeric Data:\n",
    "\n",
    "The statistics provided by df.describe() only apply to numeric data by default, as mean, standard deviation, and percentiles cannot be calculated for categorical or non-numeric data. You can, however, include non-numeric data by using df.describe(include=['object']).\n",
    "Code Examples Shared:\n",
    "Loading and Summarizing the Dataset:\n",
    "\n",
    "python\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv('path_to_your_file.csv')\n",
    "\n",
    "\n",
    "print(\"Shape of the dataset (rows, columns):\", data.shape)\n",
    "\n",
    "print(\"\\nSummary of numeric columns:\\n\", data.describe())\n",
    "Using value_counts() for Categorical and Numeric Columns:\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nValue counts for column 'q2':\\n\", data['q2'].value_counts())\n",
    "\n",
    "print(\"\\nValue counts for column 'q4':\\n\", data['q4'].value_counts())\n",
    "Coding Results Summary:\n",
    "Shape of the Dataset:\n",
    "he dataset (rows, columns): (number of rows, number of columns)\n",
    "Summary of Numeric Columns:\n",
    "\n",
    "python\n",
    "Summary of numeric columns:\n",
    "    subject_id       q1        q4\n",
    "count    20.0         15        18\n",
    "mean    1010.5        5.5       6.2\n",
    "std       5.91        1.8       3.2\n",
    "min     1001          3.0       1.0\n",
    "25%     1005.75       4.0       4.0\n",
    "50%     1010.5        5.0       5.0\n",
    "75%     1015.25       7.0       8.0\n",
    "max     1020          9.0      12.0\n",
    "Value Counts for q2 and q4:\n",
    "\n",
    "python\n",
    "Value counts for column 'q2':\n",
    "Agree             5\n",
    "Disagree          5\n",
    "Strongly Agree    3\n",
    "Neutral           2\n",
    "python\n",
    "\n",
    "Value counts for column 'q4':\n",
    "5     3\n",
    "8     3\n",
    "7     2\n",
    "4     1\n",
    "12    1\n",
    "\n",
    "#chatgpt link: https://chatgpt.com/share/a67aa256-124c-46e2-a8e8-ce48aaf06c6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f7ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chatgpt link: https://chatgpt.com/share/6411f63f-8b57-4836-8606-d7d010ab125d\n",
    "              https://chatgpt.com/share/a67aa256-124c-46e2-a8e8-ce48aaf06c6c\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
